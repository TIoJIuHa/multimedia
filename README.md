# Методы, средства и технологии мультимедиа

Выполнила студентка: Елистратова П.А 
Группа: М8О-410Б-21

## Часть первая. Задача классификации.

В качестве метрик в задаче классификации использовались accuracy и f1-score. Процесс обучения описан в ноутбуке [classification.ipnb](classification.ipynb)

В таблице приведены получившиеся accuracy для разных моделей.
<table>
    <thead>
        <tr>
            <th rowspan=2>Алгоритм</th>
            <th colspan=2>Модели из sklearn</th>
            <th colspan=2>Самостоятельная реализация</th>
        </tr>
        <tr>
            <th>бейзлайн</th>
            <th>улучшенный бейзлайн</th>
            <th>бейзлайн</th>
            <th>улучшенный бейзлайн</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><b><i>KNN</i></b></td>
            <td>0.649</td>
            <td>0.682</td>
            <td>0.649</td>
            <td>0.682</td>
        </tr>
        <tr>
            <td><b><i>Логистическая регрессия</i></b></td>
            <td>0.747</td>
            <td>0.740</td>
            <td>0.714</td>
            <td>0.753</td>
        </tr>
        <tr>
            <td><b><i>Линейная регрессия</i></b></td>
            <td>0.759</td>
            <td>0.734</td>
            <td>0.643</td>
            <td>0.740</td>
        </tr>
        <tr>
            <td><b><i>Решающее дерево</i></b></td>
            <td>0.746</td>
            <td>0.753</td>
            <td>0.604</td>
            <td>0.727</td>
        </tr>
        <tr>
            <td><b><i>Случайный лес</i></b></td>
            <td>0.721</td>
            <td>0.734</td>
            <td>0.766</td>
            <td>0.772</td>
        </tr>
        <tr>
            <td><b><i>Градиентный бустинг</i></b></td>
            <td>0.740</td>
            <td>0.766</td>
            <td>0.643</td>
            <td>0.649</td>
        </tr>
    </tbody>
</table>

### Вывод

Из таблицы видно, что, в принципе, все модели показывали неплохие результаты. Однако лучшей точности удалось добиться с помощью самостоятельной реализации Случайного леса и препроцессинга данных.

------------

## Часть вторая. Задача регрессии.

В качестве метрик в задаче классификации использовались MSE и f2-score. Процесс обучения описан в ноутбуке [regression.ipnb](regression.ipynb)

В таблице приведены получившиеся MSE для разных моделей.
<table>
    <thead>
        <tr>
            <th rowspan=2>Алгоритм</th>
            <th colspan=2>Модели из sklearn</th>
            <th colspan=2>Самостоятельная реализация</th>
        </tr>
        <tr>
            <th>бейзлайн</th>
            <th>улучшенный бейзлайн</th>
            <th>бейзлайн</th>
            <th>улучшенный бейзлайн</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><b><i>KNN</i></b></td>
            <td>4.958</td>
            <td>4.918</td>
            <td>6.839</td>
            <td>7.058</td>
        </tr>
        <tr>
            <td><b><i>Логистическая регрессия</i></b></td>
            <td>5.736</td>
            <td>5.687</td>
            <td>86.774</td>
            <td>92.403</td>
        </tr>
        <tr>
            <td><b><i>Линейная регрессия</i></b></td>
            <td>4.649</td>
            <td>4.695</td>
            <td>4.649</td>
            <td>4.705</td>
        </tr>
        <tr>
            <td><b><i>Решающее дерево</i></b></td>
            <td>8.436</td>
            <td>5.513</td>
            <td>5.600</td>
            <td>6.935</td>
        </tr>
        <tr>
            <td><b><i>Случайный лес</i></b></td>
            <td>4.446</td>
            <td>4.300</td>
            <td>4.709</td>
            <td>4.885</td>
        </tr>
        <tr>
            <td><b><i>Градиентный бустинг</i></b></td>
            <td>4.417</td>
            <td>4.576</td>
            <td>4.408</td>
            <td>4.557</td>
        </tr>
    </tbody>
</table>

### Вывод
Из таблицы видно, что при улучшении бейзлайна метрики стандартных моделей в целом тоже улучшаются. К сожалению не удалось реализовать самостоятельно модели, которые бы показывали лучшие результаты, чем из модели из sklearn. Возможно следует применить ещё оптимизации и улучшить алгоритм подбора гиперпараметров для повышения качества модели.